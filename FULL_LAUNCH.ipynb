{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rapidfuzz in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (8.3.28)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (4.67.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ultralytics) (2.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: easyocr in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (0.17.2)\n",
      "Requirement already satisfied: opencv-python-headless in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.13.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (11.0.0)\n",
      "Requirement already satisfied: scikit-image in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (0.6.3)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (2024.10.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->easyocr) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->easyocr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->easyocr) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch->easyocr) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-Levenshtein in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.26.1)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-Levenshtein) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fuzzywuzzy\n",
    "%pip install rapidfuzz\n",
    "%pip install pandas\n",
    "%pip install ultralytics\n",
    "%pip install easyocr\n",
    "%pip install python-Levenshtein\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import cv2\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_path = 'test/imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка обученной модели YOLOv8\n",
    "model = YOLO(\"best.pt\")  # замените на вашу лучшую модель\n",
    "\n",
    "# Инициализация EasyOCR\n",
    "reader = easyocr.Reader(['en'])  # добавьте 'ru' для русского текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(recognized_data, output_csv=\"submission.csv\"):\n",
    "    # Преобразуем список данных в DataFrame\n",
    "    df = pd.DataFrame(recognized_data, columns=[\"image_file\", \"label\", \"label_text\"])\n",
    "    # Сохраняем DataFrame в CSV файл\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_average_similar_detections(detections, threshold=0.015):\n",
    "    filtered_detections = []\n",
    "\n",
    "    for det in detections:\n",
    "        det.insert(0,0)\n",
    "\n",
    "        x_center, y_center, width, height = det[1:5]\n",
    "        is_similar = False\n",
    "\n",
    "        # Проверяем каждую детекцию на схожесть с уже добавленными в filtered_detections\n",
    "        for i, fd in enumerate(filtered_detections):\n",
    "            fd_x_center = fd[1]\n",
    "            \n",
    "            # Проверяем схожесть только по координате x_center\n",
    "            if abs(x_center - fd_x_center) < threshold:\n",
    "                # Если схожие детекции найдены, усредняем значения\n",
    "                avg_detection = [\n",
    "                    det[0],  # Класс остается тем же\n",
    "                    np.mean([x_center, fd_x_center]),\n",
    "                    np.mean([y_center, fd[2]]),\n",
    "                    np.mean([width, fd[3]]),\n",
    "                    np.mean([height, fd[4]])\n",
    "                ]\n",
    "                \n",
    "                # Заменяем старую детекцию на усреднённую\n",
    "                filtered_detections[i] = avg_detection\n",
    "                is_similar = True\n",
    "                break\n",
    "\n",
    "        # Если похожей детекции не было найдено, добавляем текущую как новую\n",
    "        if not is_similar:\n",
    "            filtered_detections.append(det)\n",
    "    \n",
    "    return filtered_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_recognize_text_in_folder(folder_path):\n",
    "    # Загружаем базу данных для сравнения\n",
    "    df = pd.read_csv(\"grounded true train.csv\")\n",
    "    database_numbers = df[\"label_text\"].tolist()\n",
    "\n",
    "    recognized_data = []\n",
    "\n",
    "    # Обрабатываем все изображения в папке\n",
    "    for image_path in glob.glob(f\"{folder_path}/*.JPG\"):\n",
    "        # Выполняем детекцию текстовых областей с YOLOv8\n",
    "        results = model(image_path)\n",
    "        detections = results[0].boxes.xywhn  # YOLO формат (нормализованные координаты: x_center, y_center, width, height)\n",
    "\n",
    "        # Преобразуем detections в список\n",
    "        detections = detections.tolist()\n",
    "\n",
    "        # Применяем фильтрацию для похожих детекций\n",
    "        filtered_detections = filter_and_average_similar_detections(detections)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        img_h, img_w = image.shape[:2]\n",
    "\n",
    "        detected_texts = []\n",
    "        labels = []\n",
    "\n",
    "        # Обработка каждого обнаруженного текстового блока\n",
    "        for box in filtered_detections:\n",
    "            x_center, y_center, width, height = box[1:5]\n",
    "            \n",
    "            # Преобразование координат из нормализованных в пиксельные\n",
    "            x_center_pix = int(x_center * img_w)\n",
    "            y_center_pix = int(y_center * img_h)\n",
    "            width_pix = int(width * img_w)\n",
    "            height_pix = int(height * img_h)\n",
    "\n",
    "            x1 = int((x_center - width / 2) * img_w)\n",
    "            y1 = int((y_center - height / 2) * img_h)\n",
    "            x2 = int((x_center + width / 2) * img_w)\n",
    "            y2 = int((y_center + height / 2) * img_h)\n",
    "\n",
    "            cropped_image = image[y1:y2, x1:x2]  # Вырезаем область с текстом\n",
    "\n",
    "            # Применяем OCR к обрезанному изображению\n",
    "            text = reader.readtext(cropped_image, detail=0)\n",
    "            detected_texts.extend(text)  # Добавляем результаты OCR\n",
    "\n",
    "            # Сохраняем координаты рамки в формате YOLO (по пикселям)\n",
    "            labels.append([0, x_center_pix / img_w, y_center_pix / img_h, width_pix / img_w, height_pix / img_h])\n",
    "\n",
    "            # Рисуем рамку на изображении для визуализации\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Объединяем распознанный текст в одну строку\n",
    "        detected_number = ' '.join(detected_texts)\n",
    "\n",
    "        # Находим лучшее совпадение с базой данных\n",
    "        best_partial_match = process.extractOne(detected_number, database_numbers, scorer=fuzz.partial_ratio)\n",
    "        mark = best_partial_match[0]\n",
    "\n",
    "        labels = '\\n'.join(''.join(map(str, row)) for row in labels)\n",
    "        # Сохраняем результат в список\n",
    "        recognized_data.append({\n",
    "            \"image_file\": image_path.split('/')[-1],\n",
    "            \"label\": labels,\n",
    "            \"label_text\": mark.strip('\"')  # Удаляем лишние кавычки, если они есть\n",
    "        })\n",
    "\n",
    "        # Сохраняем изображение с нарисованными рамками\n",
    "        cv2.imwrite(f\"output/{image_path.split('/')[-1]}\", image)\n",
    "\n",
    "    # Сохраняем результаты в JSON файл\n",
    "    save_results_to_csv(recognized_data)\n",
    "\n",
    "    return recognized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new2.JPG: 480x640 1 text, 343.3ms\n",
      "Speed: 5.0ms preprocess, 343.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new137.JPG: 480x640 1 text, 302.1ms\n",
      "Speed: 2.1ms preprocess, 302.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new123.JPG: 640x480 1 text, 216.4ms\n",
      "Speed: 1.8ms preprocess, 216.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new86.JPG: 640x480 1 text, 305.3ms\n",
      "Speed: 2.2ms preprocess, 305.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new92.JPG: 480x640 1 text, 269.1ms\n",
      "Speed: 2.3ms preprocess, 269.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new79.JPG: 640x480 2 texts, 217.4ms\n",
      "Speed: 1.7ms preprocess, 217.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new78.JPG: 480x640 1 text, 202.3ms\n",
      "Speed: 1.6ms preprocess, 202.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new122.JPG: 640x480 1 text, 180.2ms\n",
      "Speed: 1.5ms preprocess, 180.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new136.JPG: 640x480 2 texts, 194.2ms\n",
      "Speed: 1.9ms preprocess, 194.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new3.JPG: 480x640 1 text, 194.4ms\n",
      "Speed: 3.4ms preprocess, 194.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new108.JPG: 640x480 1 text, 183.4ms\n",
      "Speed: 1.7ms preprocess, 183.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new134.JPG: 640x480 1 text, 186.6ms\n",
      "Speed: 1.7ms preprocess, 186.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new91.JPG: 640x480 1 text, 195.7ms\n",
      "Speed: 2.3ms preprocess, 195.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new46.JPG: 640x480 1 text, 195.6ms\n",
      "Speed: 1.9ms preprocess, 195.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new47.JPG: 640x480 1 text, 177.6ms\n",
      "Speed: 1.7ms preprocess, 177.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new90.JPG: 640x480 1 text, 184.8ms\n",
      "Speed: 1.7ms preprocess, 184.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new135.JPG: 640x480 1 text, 191.7ms\n",
      "Speed: 1.5ms preprocess, 191.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new121.JPG: 640x480 1 text, 203.8ms\n",
      "Speed: 3.1ms preprocess, 203.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new109.JPG: 640x480 1 text, 214.3ms\n",
      "Speed: 2.6ms preprocess, 214.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new125.JPG: 640x480 1 text, 194.1ms\n",
      "Speed: 1.8ms preprocess, 194.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new94.JPG: 640x480 1 text, 198.4ms\n",
      "Speed: 2.4ms preprocess, 198.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new80.JPG: 640x480 1 text, 208.3ms\n",
      "Speed: 2.2ms preprocess, 208.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new57.JPG: 480x640 1 text, 192.7ms\n",
      "Speed: 1.8ms preprocess, 192.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new42.JPG: 640x480 1 text, 195.4ms\n",
      "Speed: 1.8ms preprocess, 195.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new56.JPG: 640x480 1 text, 290.8ms\n",
      "Speed: 3.4ms preprocess, 290.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new81.JPG: 480x640 (no detections), 197.8ms\n",
      "Speed: 1.8ms preprocess, 197.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new95.JPG: 640x480 1 text, 202.3ms\n",
      "Speed: 2.3ms preprocess, 202.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new130.JPG: 480x640 1 text, 204.0ms\n",
      "Speed: 2.4ms preprocess, 204.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new124.JPG: 640x480 1 text, 213.3ms\n",
      "Speed: 2.0ms preprocess, 213.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new126.JPG: 480x640 1 text, 206.3ms\n",
      "Speed: 3.2ms preprocess, 206.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new97.JPG: 640x480 1 text, 194.4ms\n",
      "Speed: 1.6ms preprocess, 194.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new68.JPG: 640x480 1 text, 196.7ms\n",
      "Speed: 2.7ms preprocess, 196.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new54.JPG: 640x480 1 text, 286.9ms\n",
      "Speed: 3.1ms preprocess, 286.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new55.JPG: 640x480 1 text, 241.8ms\n",
      "Speed: 3.6ms preprocess, 241.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new69.JPG: 640x480 5 texts, 240.4ms\n",
      "Speed: 6.3ms preprocess, 240.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new96.JPG: 640x480 1 text, 227.3ms\n",
      "Speed: 1.5ms preprocess, 227.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new82.JPG: 480x640 1 text, 180.8ms\n",
      "Speed: 3.1ms preprocess, 180.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new127.JPG: 640x480 2 texts, 212.9ms\n",
      "Speed: 1.8ms preprocess, 212.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new133.JPG: 640x480 1 text, 317.4ms\n",
      "Speed: 1.6ms preprocess, 317.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new168.JPG: 480x640 2 texts, 251.6ms\n",
      "Speed: 5.3ms preprocess, 251.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new140.JPG: 640x480 1 text, 333.4ms\n",
      "Speed: 1.7ms preprocess, 333.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new32.JPG: 480x640 (no detections), 344.8ms\n",
      "Speed: 3.1ms preprocess, 344.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new141.JPG: 640x480 1 text, 376.0ms\n",
      "Speed: 3.2ms preprocess, 376.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new143.JPG: 640x480 1 text, 274.2ms\n",
      "Speed: 2.9ms preprocess, 274.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new31.JPG: 480x640 2 texts, 321.9ms\n",
      "Speed: 3.4ms preprocess, 321.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new24.JPG: 640x512 1 text, 247.2ms\n",
      "Speed: 3.7ms preprocess, 247.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new30.JPG: 480x640 1 text, 646.5ms\n",
      "Speed: 3.1ms preprocess, 646.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new156.JPG: 480x640 1 text, 382.9ms\n",
      "Speed: 3.0ms preprocess, 382.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new142.JPG: 640x480 1 text, 178.7ms\n",
      "Speed: 1.5ms preprocess, 178.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new146.JPG: 640x480 1 text, 200.2ms\n",
      "Speed: 2.3ms preprocess, 200.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new152.JPG: 480x640 1 text, 234.6ms\n",
      "Speed: 2.7ms preprocess, 234.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new35.JPG: 480x640 2 texts, 196.5ms\n",
      "Speed: 1.5ms preprocess, 196.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new147.JPG: 640x480 1 text, 185.4ms\n",
      "Speed: 2.8ms preprocess, 185.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new151.JPG: 640x480 1 text, 529.6ms\n",
      "Speed: 2.6ms preprocess, 529.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new145.JPG: 640x480 1 text, 390.6ms\n",
      "Speed: 4.1ms preprocess, 390.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new23.JPG: 384x640 2 texts, 300.8ms\n",
      "Speed: 4.5ms preprocess, 300.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new37.JPG: 480x640 2 texts, 206.2ms\n",
      "Speed: 2.5ms preprocess, 206.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new144.JPG: 640x480 2 texts, 449.9ms\n",
      "Speed: 1.7ms preprocess, 449.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new150.JPG: 640x480 1 text, 323.8ms\n",
      "Speed: 1.9ms preprocess, 323.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new149.JPG: 640x480 1 text, 418.5ms\n",
      "Speed: 13.3ms preprocess, 418.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new161.JPG: 640x480 1 text, 263.6ms\n",
      "Speed: 3.8ms preprocess, 263.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new160.JPG: 640x480 5 texts, 224.8ms\n",
      "Speed: 3.1ms preprocess, 224.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new148.JPG: 480x640 1 text, 264.8ms\n",
      "Speed: 2.4ms preprocess, 264.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new11.JPG: 640x480 1 text, 202.3ms\n",
      "Speed: 1.8ms preprocess, 202.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new163.JPG: 640x480 2 texts, 204.0ms\n",
      "Speed: 2.2ms preprocess, 204.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new29.JPG: 480x640 2 texts, 228.2ms\n",
      "Speed: 2.5ms preprocess, 228.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new15.JPG: 640x480 1 text, 199.8ms\n",
      "Speed: 1.5ms preprocess, 199.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new14.JPG: 640x480 1 text, 205.1ms\n",
      "Speed: 3.0ms preprocess, 205.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new28.JPG: 480x640 (no detections), 227.0ms\n",
      "Speed: 3.0ms preprocess, 227.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new164.JPG: 480x640 1 text, 216.1ms\n",
      "Speed: 3.4ms preprocess, 216.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new158.JPG: 480x640 2 texts, 223.5ms\n",
      "Speed: 2.5ms preprocess, 223.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new17.JPG: 640x480 1 text, 210.9ms\n",
      "Speed: 1.7ms preprocess, 210.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new159.JPG: 480x640 1 text, 239.2ms\n",
      "Speed: 3.2ms preprocess, 239.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new116.JPG: 640x480 1 text, 190.2ms\n",
      "Speed: 1.8ms preprocess, 190.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new102.JPG: 640x480 1 text, 203.2ms\n",
      "Speed: 2.3ms preprocess, 203.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new58.JPG: 640x480 1 text, 217.5ms\n",
      "Speed: 3.0ms preprocess, 217.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new59.JPG: 640x480 1 text, 241.1ms\n",
      "Speed: 3.0ms preprocess, 241.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new65.JPG: 480x640 1 text, 226.3ms\n",
      "Speed: 2.5ms preprocess, 226.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new103.JPG: 640x480 1 text, 219.9ms\n",
      "Speed: 2.8ms preprocess, 219.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new117.JPG: 640x480 1 text, 220.9ms\n",
      "Speed: 2.4ms preprocess, 220.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new101.JPG: 640x480 1 text, 211.1ms\n",
      "Speed: 2.5ms preprocess, 211.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new115.JPG: 480x640 (no detections), 223.3ms\n",
      "Speed: 2.5ms preprocess, 223.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new98.JPG: 640x480 1 text, 219.8ms\n",
      "Speed: 2.1ms preprocess, 219.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new99.JPG: 640x480 1 text, 245.7ms\n",
      "Speed: 3.5ms preprocess, 245.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new114.JPG: 640x480 1 text, 213.3ms\n",
      "Speed: 2.1ms preprocess, 213.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new100.JPG: 640x480 1 text, 213.9ms\n",
      "Speed: 2.0ms preprocess, 213.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new128.JPG: 640x480 1 text, 201.1ms\n",
      "Speed: 1.6ms preprocess, 201.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new110.JPG: 640x480 1 text, 241.0ms\n",
      "Speed: 3.7ms preprocess, 241.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new138.JPG: 640x480 1 text, 206.2ms\n",
      "Speed: 2.1ms preprocess, 206.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new62.JPG: 288x640 1 text, 224.7ms\n",
      "Speed: 1.9ms preprocess, 224.7ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new77.JPG: 608x640 2 texts, 296.8ms\n",
      "Speed: 6.4ms preprocess, 296.8ms inference, 0.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new88.JPG: 640x480 1 text, 201.9ms\n",
      "Speed: 2.8ms preprocess, 201.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new139.JPG: 640x480 1 text, 182.5ms\n",
      "Speed: 1.5ms preprocess, 182.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new111.JPG: 640x480 2 texts, 242.0ms\n",
      "Speed: 1.6ms preprocess, 242.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new105.JPG: 640x480 1 text, 192.1ms\n",
      "Speed: 1.6ms preprocess, 192.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new113.JPG: 640x480 1 text, 205.7ms\n",
      "Speed: 1.7ms preprocess, 205.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new107.JPG: 640x480 1 text, 243.5ms\n",
      "Speed: 2.4ms preprocess, 243.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new61.JPG: 640x480 1 text, 214.9ms\n",
      "Speed: 2.5ms preprocess, 214.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new60.JPG: 640x480 (no detections), 207.5ms\n",
      "Speed: 2.6ms preprocess, 207.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new106.JPG: 640x480 1 text, 223.1ms\n",
      "Speed: 2.0ms preprocess, 223.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/andrew/Desktop/TEXTHACK/test/imgs/new112.JPG: 640x480 1 text, 203.6ms\n",
      "Speed: 1.7ms preprocess, 203.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Запускаем обработку папки\n",
    "results = detect_and_recognize_text_in_folder(f\"{your_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
